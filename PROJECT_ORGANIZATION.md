# üóÇÔ∏è PROJECT ORGANIZATION - COMPLETE PIPELINE STRUCTURE

**Project**: Lightweight AI for Maritime CAN Intrusion Detection  
**Date**: 10 November 2025  
**Status**: Phase 0 ‚úÖ | Phase 1 ‚úÖ | Phase 2 ‚è≥ | Phase 3 ‚è≥

---

## üìÅ DIRECTORY STRUCTURE

```
Lightweight_IA_V_2/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ scripts/                          ‚Üê Entry point scripts (run these!)
‚îÇ   ‚îú‚îÄ‚îÄ 00_validate_setup.py             ‚Üê Check environment is ready
‚îÇ   ‚îú‚îÄ‚îÄ 01_initialize.py                 ‚Üê PHASE 0: Signal selection (EMPTY - not needed)
‚îÇ   ‚îú‚îÄ‚îÄ 02_preprocess_data.py            ‚Üê PHASE 1: Create windows (EMPTY - not needed)
‚îÇ   ‚îú‚îÄ‚îÄ decode_brute_frames.py           ‚Üê PHASE -1: Decode raw CAN frames
‚îÇ   ‚îú‚îÄ‚îÄ merge_n2k_files.py               ‚Üê Utility: Merge multiple CAN logs
‚îÇ   ‚îî‚îÄ‚îÄ 00_generate_dummy_data.py        ‚Üê Testing: Create synthetic data
‚îÇ
‚îú‚îÄ‚îÄ üìÇ src/                              ‚Üê Core Python modules (imported by scripts)
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ initialization/               ‚Üê PHASE 0 modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ signal_selector.py           ‚Üê Remove low-quality signals
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ correlation_analyzer.py      ‚Üê Compute Pearson correlation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ signal_reorderer.py          ‚Üê Preserve signal order for CNN
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ preprocessing/                ‚Üê PHASE 1 modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ n2k_decoder.py               ‚Üê NMEA 2000 protocol decoder (pure Python)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fifo_queue.py                ‚Üê Forward-fill missing values
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ view_builder.py              ‚Üê Create multi-scale sliding windows
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normalizer.py                ‚Üê Min-max scaling [0,1]
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ training/                     ‚Üê PHASE 2 modules (EMPTY - to be created)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (empty)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ detection/                    ‚Üê PHASE 3 modules (EMPTY - to be created)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (empty)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ models/                       ‚Üê CNN architectures
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (to be created)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ evaluation/                   ‚Üê Performance metrics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (empty)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ utils/                        ‚Üê Shared utilities
‚îÇ       ‚îî‚îÄ‚îÄ (helpers, constants, etc.)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ results/                          ‚Üê All outputs organized by phase
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ raw_frames/                   ‚Üê PHASE -1 output
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ brute_frames.csv             ‚Üê Raw CAN frames (154,161 frames)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ fixed_decoder_data/           ‚Üê PHASE -1 output
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ decoded_brute_frames.csv     ‚Üê Decoded messages (98,942 √ó 23 columns)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ initialization/               ‚Üê PHASE 0 outputs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ signal_order.txt             ‚Üê 15 selected signals IN ORDER
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ correlation_matrix.csv       ‚Üê 15√ó15 Pearson correlations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ correlation_heatmap.png      ‚Üê Visual correlation matrix
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dendrogram.png               ‚Üê Hierarchical clustering
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_quality_report.txt      ‚Üê Per-signal statistics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ initialization_summary.txt   ‚Üê Human-readable summary
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ preprocessing/                ‚Üê PHASE 1 outputs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ windows/                  ‚Üê Training-ready data
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ windows_T1.npy           ‚Üê 98,893 windows (stride=1)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ windows_T5.npy           ‚Üê 19,740 windows (stride=5)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ windows_T10.npy          ‚Üê 9,846 windows (stride=10)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ windows_T20.npy          ‚Üê 4,899 windows (stride=20)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ windows_T50.npy          ‚Üê 1,930 windows (stride=50)
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ parameters/               ‚Üê Normalization configs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ norm_params_T1.csv       ‚Üê Min/max for T=1
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ norm_params_T5.csv       ‚Üê Min/max for T=5
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ norm_params_T10.csv      ‚Üê Min/max for T=10
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ norm_params_T20.csv      ‚Üê Min/max for T=20
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ norm_params_T50.csv      ‚Üê Min/max for T=50
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ visualizations/           ‚Üê Quality plots (10 PNG files)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_real_signals_timeseries.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_normalization_effect.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_multiscale_*.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_distribution_*.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 05_sample_window_heatmap.png
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing_summary.txt    ‚Üê Phase 1 summary
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ training/                     ‚Üê PHASE 2 outputs (to be created)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autoencoder_T1.h5        ‚Üê Trained model for T=1
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autoencoder_T5.h5
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autoencoder_T10.h5
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autoencoder_T20.h5
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ autoencoder_T50.h5
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ thresholds/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ thresholds_T1.json       ‚Üê Anomaly thresholds
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ training_history/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ history_T1.csv           ‚Üê Training loss curves
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÇ visualizations/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ training_loss_T1.png
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ reconstruction_error_distribution_T1.png
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ detection/                    ‚Üê PHASE 3 outputs (to be created)
‚îÇ       ‚îú‚îÄ‚îÄ üìÇ test_results/
‚îÇ       ‚îú‚îÄ‚îÄ üìÇ attack_detection/
‚îÇ       ‚îî‚îÄ‚îÄ üìÇ confusion_matrices/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ CANShield/                        ‚Üê Reference implementation (original paper)
‚îÇ   ‚îî‚îÄ‚îÄ src/                             ‚Üê Contains modules we can reference
‚îÇ
‚îú‚îÄ‚îÄ üìÇ docs/                             ‚Üê Documentation
‚îÇ   ‚îú‚îÄ‚îÄ PHASE_0_INITIALIZATION_DETAILED_WALKTHROUGH.md  ‚Üê ‚úÖ Just created
‚îÇ   ‚îî‚îÄ‚îÄ PHASE_1_PREPROCESSING_DETAILED_WALKTHROUGH.md   ‚Üê ‚úÖ Just created
‚îÇ
‚îú‚îÄ‚îÄ üìÇ config/                           ‚Üê Configuration files
‚îÇ   ‚îî‚îÄ‚îÄ (YAML configs for training hyperparameters)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ models/                           ‚Üê Saved trained models
‚îÇ   ‚îî‚îÄ‚îÄ (will contain .h5 or .keras files)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ notebooks/                        ‚Üê Jupyter notebooks for exploration
‚îÇ   ‚îî‚îÄ‚îÄ (interactive analysis)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ tests/                            ‚Üê Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ (pytest files)
‚îÇ
‚îú‚îÄ‚îÄ üìú run_preprocessing_REAL_DATA.py    ‚Üê **MAIN SCRIPT for Phase 1** ‚úÖ
‚îú‚îÄ‚îÄ üìú requirements.txt                  ‚Üê Python dependencies
‚îú‚îÄ‚îÄ üìú README.md                         ‚Üê Project overview
‚îî‚îÄ‚îÄ üìú .gitignore                        ‚Üê Git ignore rules
```

---

## üîÑ PHASE EXECUTION FLOW

### **The ACTUAL workflow you've been following:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                            COMPLETE PIPELINE                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

PHASE -1: DECODING (Raw CAN ‚Üí Decoded Messages)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Script:  scripts/decode_brute_frames.py
Input:   results/raw_frames/brute_frames.csv (154,161 raw CAN frames)
Process: Parse NMEA 2000 protocol (PGN extraction, byte parsing)
Output:  results/fixed_decoder_data/decoded_brute_frames.csv
         (98,942 messages √ó 23 columns)
Status:  ‚úÖ DONE

         ‚Üì

PHASE 0: INITIALIZATION (Signal Quality Analysis)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Script:  Custom Python script (ad-hoc, not in scripts/)
Modules: src/initialization/
         - signal_selector.py
         - correlation_analyzer.py
         - signal_reorderer.py
Input:   results/fixed_decoder_data/decoded_brute_frames.csv
Process: 1. Check coverage (>95% threshold)
         2. Remove constant signals
         3. Remove duplicates (GNSS lat/lon)
         4. Compute correlation matrix
         5. Hierarchical clustering
         6. Select 15/23 signals
Output:  results/initialization/
         - signal_order.txt (15 signals)
         - correlation_heatmap.png
         - dendrogram.png
         - data_quality_report.txt
Status:  ‚úÖ DONE
Docs:    PHASE_0_INITIALIZATION_DETAILED_WALKTHROUGH.md

         ‚Üì

PHASE 1: PREPROCESSING (Multi-Scale Window Creation)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Script:  run_preprocessing_REAL_DATA.py  ‚Üê **YOU RAN THIS!**
Modules: src/preprocessing/
         - fifo_queue.py (forward-fill)
         - view_builder.py (sliding windows)
         - normalizer.py (min-max scaling)
Input:   - decoded_brute_frames.csv
         - signal_order.txt
Process: 1. Load 15 selected signals
         2. Forward-fill missing values
         3. Create sliding windows:
            ‚Ä¢ T=1:  stride=1  ‚Üí 98,893 windows
            ‚Ä¢ T=5:  stride=5  ‚Üí 19,740 windows
            ‚Ä¢ T=10: stride=10 ‚Üí 9,846 windows
            ‚Ä¢ T=20: stride=20 ‚Üí 4,899 windows
            ‚Ä¢ T=50: stride=50 ‚Üí 1,930 windows
         4. Normalize to [0,1]
         5. Save .npy files
         6. Generate visualizations
Output:  results/preprocessing/
         - windows/*.npy (5 files, 165 MB)
         - parameters/norm_params_T*.csv (5 files)
         - visualizations/*.png (10 plots)
Status:  ‚úÖ DONE
Docs:    PHASE_1_PREPROCESSING_DETAILED_WALKTHROUGH.md

         ‚Üì

PHASE 2: CNN TRAINING (Autoencoder Learning)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Script:  scripts/03_train_autoencoders.py  ‚Üê **TO BE CREATED**
Modules: src/training/
         - autoencoder_builder.py  ‚Üê Build CNN architecture
         - trainer.py              ‚Üê Training loop
         - threshold_calculator.py ‚Üê Compute anomaly thresholds
Input:   results/preprocessing/windows/*.npy (5 files)
Process: For each time scale (T=1,5,10,20,50):
         1. Load windows
         2. Split train/validation (80/20)
         3. Build CNN autoencoder:
            ‚Ä¢ Encoder: Conv1D layers ‚Üí bottleneck
            ‚Ä¢ Decoder: Conv1DTranspose ‚Üí reconstruction
         4. Train with MSE loss
         5. Compute thresholds:
            ‚Ä¢ Œº + 2œÉ (95% confidence)
            ‚Ä¢ Œº + 3œÉ (99.7% confidence)
            ‚Ä¢ 99.5 percentile
         6. Save model (.h5 file)
         7. Plot training curves
Output:  results/training/
         - models/autoencoder_T*.h5 (5 models)
         - thresholds/thresholds_T*.json (5 JSON files)
         - training_history/history_T*.csv
         - visualizations/*.png
Status:  ‚è≥ NEXT STEP
Docs:    PHASE_2_TRAINING_DETAILED_WALKTHROUGH.md (to be created)

         ‚Üì

PHASE 3: DETECTION (Real-Time Intrusion Detection)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Script:  scripts/04_detect_intrusions.py  ‚Üê **TO BE CREATED**
Modules: src/detection/
         - online_detector.py      ‚Üê Real-time inference
         - threshold_checker.py    ‚Üê Compare errors to thresholds
         - alert_generator.py      ‚Üê Generate intrusion alerts
Input:   - Trained models (results/training/models/*.h5)
         - Thresholds (results/training/thresholds/*.json)
         - New CAN data (test set or live stream)
Process: 1. Load 5 trained autoencoders
         2. Load thresholds
         3. For each incoming window:
            ‚Ä¢ Forward pass through autoencoder
            ‚Ä¢ Compute reconstruction error
            ‚Ä¢ Compare to threshold
            ‚Ä¢ If error > threshold ‚Üí ALERT!
         4. Multi-scale voting:
            ‚Ä¢ If 3/5 models detect anomaly ‚Üí Intrusion confirmed
         5. Log detections
Output:  results/detection/
         - test_results.csv (per-window predictions)
         - attack_detection_report.txt
         - confusion_matrix.png
         - ROC_curves.png
Status:  ‚è≥ PENDING (after Phase 2)
Docs:    PHASE_3_DETECTION_DETAILED_WALKTHROUGH.md (to be created)
```

---

## üéØ HOW PHASES ARE "SETTLED" (CURRENT STATE)

### **What you've actually executed:**

| Phase | Status | Script Used | Location | Output |
|-------|--------|-------------|----------|--------|
| **Phase -1** | ‚úÖ DONE | `scripts/decode_brute_frames.py` | Uses `src/preprocessing/n2k_decoder.py` | `results/fixed_decoder_data/` |
| **Phase 0** | ‚úÖ DONE | **Ad-hoc Python** (terminal commands) | Used `src/initialization/*` modules | `results/initialization/` |
| **Phase 1** | ‚úÖ DONE | **`run_preprocessing_REAL_DATA.py`** (root dir) | Uses `src/preprocessing/*` | `results/preprocessing/` |
| **Phase 2** | ‚è≥ TODO | Not created yet | Will use `src/training/*` (empty) | `results/training/` |
| **Phase 3** | ‚è≥ TODO | Not created yet | Will use `src/detection/*` (empty) | `results/detection/` |

### **Why some scripts/ are empty?**

You noticed `scripts/01_initialize.py` and `scripts/02_preprocess_data.py` are **empty**. That's because:

1. **Phase 0 (Initialization)**: You ran it **manually via terminal** using Python REPL commands, not a script
2. **Phase 1 (Preprocessing)**: You used **`run_preprocessing_REAL_DATA.py`** in the **root directory**, not `scripts/02_preprocess_data.py`

### **What SHOULD happen (clean organization):**

**Option A: Move main script to scripts/ (recommended)**
```bash
mv run_preprocessing_REAL_DATA.py scripts/02_preprocess_data.py
```

**Option B: Keep root scripts + create wrappers**
```python
# scripts/02_preprocess_data.py
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))
from run_preprocessing_REAL_DATA import main
main()
```

---

## üì¶ MODULE ORGANIZATION

### **src/initialization/** (Phase 0)

```python
# signal_selector.py
class SignalSelector:
    def remove_low_coverage(data, threshold=0.95)
    def remove_constant_signals(data)
    def remove_duplicates(data)

# correlation_analyzer.py
class CorrelationAnalyzer:
    def compute_correlation_matrix(data)
    def plot_heatmap(matrix)
    def hierarchical_clustering(matrix)

# signal_reorderer.py
def save_signal_order(signals, filepath)
def load_signal_order(filepath)
```

### **src/preprocessing/** (Phase 1)

```python
# n2k_decoder.py
class N2KDecoder:
    def decode_heading(pgn, data)
    def decode_attitude(pgn, data)
    def decode_rudder(pgn, data)
    # ... 10+ PGN decoders

# fifo_queue.py
class FIFOQueue:
    def forward_fill(data)
    def validate_no_nan(data)

# view_builder.py
class ViewBuilder:
    def create_sliding_windows(data, length=50, stride=1)
    def create_multi_scale_views(data, scales=[1,5,10,20,50])

# normalizer.py
class Normalizer:
    def fit(data)  # Compute min/max
    def transform(data)  # Apply normalization
    def save_params(filepath)  # Save for inference
```

### **src/training/** (Phase 2 - TO CREATE)

```python
# autoencoder_builder.py
class AutoencoderBuilder:
    def build_1d_cnn_autoencoder(input_shape)
    def compile_model(model, optimizer, loss)

# trainer.py
class AutoencoderTrainer:
    def train(model, train_data, val_data, epochs)
    def save_model(model, filepath)
    def plot_training_history(history)

# threshold_calculator.py
class ThresholdCalculator:
    def compute_reconstruction_errors(model, data)
    def calculate_statistical_thresholds(errors)
    def save_thresholds(thresholds, filepath)
```

### **src/detection/** (Phase 3 - TO CREATE)

```python
# online_detector.py
class OnlineDetector:
    def load_models(model_paths)
    def load_thresholds(threshold_paths)
    def predict_window(window)
    def multi_scale_voting(predictions)

# threshold_checker.py
class ThresholdChecker:
    def check_threshold(error, threshold)
    def generate_alert(window_id, time, signal)

# alert_generator.py
class AlertGenerator:
    def log_intrusion(detection_info)
    def send_alert(message)
```

---

## üöÄ NEXT STEPS TO ORGANIZE

### **Immediate actions:**

1. **Clean up script organization:**
   ```bash
   # Move Phase 1 script to scripts/
   mv run_preprocessing_REAL_DATA.py scripts/02_preprocess_data.py
   
   # Create Phase 0 script (consolidate terminal commands)
   # scripts/01_initialize.py
   ```

2. **Create Phase 2 training script:**
   ```bash
   # scripts/03_train_autoencoders.py
   ```

3. **Create Phase 3 detection script:**
   ```bash
   # scripts/04_detect_intrusions.py
   ```

4. **Populate src/training/ with modules:**
   ```
   src/training/
   ‚îú‚îÄ‚îÄ __init__.py
   ‚îú‚îÄ‚îÄ autoencoder_builder.py
   ‚îú‚îÄ‚îÄ trainer.py
   ‚îî‚îÄ‚îÄ threshold_calculator.py
   ```

5. **Populate src/detection/ with modules:**
   ```
   src/detection/
   ‚îú‚îÄ‚îÄ __init__.py
   ‚îú‚îÄ‚îÄ online_detector.py
   ‚îú‚îÄ‚îÄ threshold_checker.py
   ‚îî‚îÄ‚îÄ alert_generator.py
   ```

---

## üìä CURRENT STATE SUMMARY

### **What exists and works:**

‚úÖ **Data decoding**: `results/fixed_decoder_data/decoded_brute_frames.csv` (98,942 messages)  
‚úÖ **Signal selection**: `results/initialization/signal_order.txt` (15 signals)  
‚úÖ **Preprocessed windows**: `results/preprocessing/windows/*.npy` (135,308 windows, 165 MB)  
‚úÖ **Normalization params**: `results/preprocessing/parameters/norm_params_T*.csv`  
‚úÖ **Documentation**: Phase 0 & Phase 1 detailed walkthroughs  

### **What needs to be created:**

‚è≥ **Training modules**: `src/training/*`  
‚è≥ **Detection modules**: `src/detection/*`  
‚è≥ **Training script**: `scripts/03_train_autoencoders.py`  
‚è≥ **Detection script**: `scripts/04_detect_intrusions.py`  
‚è≥ **Phase 2 documentation**: `PHASE_2_TRAINING_DETAILED_WALKTHROUGH.md`  
‚è≥ **Phase 3 documentation**: `PHASE_3_DETECTION_DETAILED_WALKTHROUGH.md`  

---

## üéì KEY INSIGHT

**Your pipeline is NOT broken!** It's just **organically evolved**:

- Phase -1: Used `scripts/decode_brute_frames.py` ‚úÖ
- Phase 0: Ran **manually** (terminal commands) ‚úÖ
- Phase 1: Used **`run_preprocessing_REAL_DATA.py`** (root dir) ‚úÖ
- Phase 2: **Next to create**
- Phase 3: **Future work**

**All outputs are in the right place:** `results/*/`

**All modules are organized:** `src/*/`

**Just need to:**
1. Create Phase 2 & 3 scripts
2. Optionally reorganize existing scripts for consistency
3. Complete the pipeline!

---

**Ready to proceed with Phase 2 training?** üöÄ
